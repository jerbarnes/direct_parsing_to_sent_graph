frameworks:
- ["darmstadt", "en"]

encoder: /cluster/projects/nn9851k/models/xlm-roberta-base
epochs: 100
n_layers: 1
query_length: 2
balance_loss_weights: false
grad_norm_lr: 3.0e-4
decoder_learning_rate: 6.0e-5
encoder_learning_rate: 3.0e-5            # initial encoder learning rate
encoder_weight_decay: 1.5e-3
label_smoothing: 0.0
encoder_delay_steps: 500
warmup_steps: 1000
char_embedding: false
dropout_word: 0.0
focal: true
hidden_size_edge_presence: 256
hidden_size_anchor: 256
dropout_anchor: 0.35
dropout_edge_presence: 0.75
dropout_label: 0.85
batch_size: 32
